experiments:
  # root: '/projects/ag-bozek/arash/gbm/experiments/'
  root: '/data/afatehi/gbm/experiments/'
  models: ['unet_3d',
           'unet_3d_me',
           'unet_3d_ss',
           'swin_unetr']
  model_sizes: [
                 [tiny, 16, 32, 64],
                 [small, 32, 64, 128],
                 [medium, 64, 128, 256],
                 [big, 64, 128, 256, 512],
                 [huge, 128, 256, 512, 1024],
               ]
  optimizers: [[adam, lr, 0.0001]]
  losses: [CrossEntropy, Dice, IoU]
  metrics: [
            ['Loss', True],
            ['Accuracy', False],
            ['Pervalence', False],
            ['BalancedAccuracy', False],
            ['TruePositiveRate', True],
            ['TrueNegativeRate', False],
            ['FalsePositiveRate', False],
            ['FalseNegativeRate', False],
            ['PositivePredictiveValue', True],
            ['NegativePredictiveValue', False],
            ['FalseDiscoveryRate', False],
            ['FalseOmissionRate', False],
            ['PositiveLikelihoodRatio', False],
            ['NegativeLikelihoodRatio', False],
            ['Dice', True],
            ['JaccardIndex', True]
           ]
  train_same_sample_size: True
  train_same_batch_size: True
  train_same_stride: False

  log_levels: [INFO, DEBUG]

  scale_lerning_rate_for_batch_size: True

  # default_data_path: '/projects/ag-bozek/arash/gbm/data/ds_human/'
  default_data_path: '/data/afatehi/gbm/data/ds_mouse/'
  default_batch_size: 8

trainer:
  model:
    name: unet_3d
    feature_maps: [64, 128, 256, 512]
    encoder_kernel: [3, 3, 3]
    encoder_padding: 'same'
    decoder_kernel: [3, 3, 3]
    decoder_padding: 'same'

  epochs: 10

  optim:
    name: adam
    lr : 0.0001

  loss: CrossEntropy
  loss_weights: [3.0, 7.0]
  report_freq: 100

  metrics: [
            'Loss',
            'TruePositiveRate',
            'PositivePredictiveValue',
            'Dice',
            'JaccardIndex',
           ]

  metrics_class_ids: [1]

  snapshot_path: ./snapshots/
  result_path: ./results-train/

  train_ds:
    path: ./data/gbm_train_ds/
    batch_size: 8
    sample_dimension: [12, 256, 256] # Z, X, Y
    pixel_stride: [1, 64, 64] # Z, X, Y
    pin_memory: True
    shuffle: True
    ignore_stride_mismatch: True
    workers: 4
    augmentation:
      enabled: True
      workers: 8
      methods: [
                ['_zoom', 2],
                ['_zoom', 1.7],
                ['_zoom', 1.3],
                ['_zoom', 0.7],
                ['_zoom', 0.5],
                ['_twist_clock', '0.5',],
                ['_twist_reverse', '0.5'],
                ['_rotate_random', '0.2'],
               ]

  valid_ds:
    path: ./data/gbm_valid_ds/
    batch_size: 8
    sample_dimension: [12, 256, 256] # Z, X, Y
    pixel_stride: [1, 128, 128] # Z, X, Y
    pin_memory: True
    shuffle: False
    ignore_stride_mismatch: True
    workers: 8

  visualization:
    enabled: True
    # The chance for a batch to create visualization
    chance: 0.30
    path: ./visuals/
    gif: True
    tif: False
    blender: True

  profiling:
    enabled: False
    path: ./profiling/
    save:
      tensorboard: True
      text: False
      print: False
    profile_memory: True
    record_shapes: True
    with_flops: True
    with_stack: False
    scheduler:
      wait: 10
      warmup: 10
      active: 4
      repeat: 4

  tensorboard:
    enabled: True
    label_seen: False
    path: ./tensorboard/

  sqlite: False

  dp: True
  device: cuda
  mixed_precision: True
  cudnn_benchmark: False

inference:
  number_class: 2
  snapshot_path: ''
  device: cuda

  post_processing:
    enabled: True
    min_size: 200
    kernel_size: 3

  morph:
    kernel_ave_size: 5

  result_dir: ''

  inference_ds:
    path: ''
    batch_size: 8
    sample_dimension: [12, 256, 256]
    pixel_stride: [1, 64, 64]
    pin_memory: True
    scale_factor: 6
    workers: 8

logging:
  log_level: INFO
  log_file: logs/train.log
  log_std: True
  log_summary: False

# All other pathes are relative to root_path
root_path: './'
